{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaiveBayes_vs_JunkMail.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOqp3niwi28up5IEosxfW1I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phuongdoan13/ML-algo-from-scratch/blob/main/NaiveBayes_vs_JunkMail.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvoL_d9SFWlF"
      },
      "source": [
        "# Introduction\n",
        "This notebook illustrates an implementation of Naive Bayes algorithm in combatting junk mail. \n",
        "\n",
        "The dataset source can be found at: https://www.kaggle.com/venky73/spam-mails-dataset. To use the code below, please download the dataset, then put it in the /content/ folder (i.e. import the data to google colab at the highest folder)\n",
        "\n",
        "Reference: https://courses.cs.washington.edu/courses/cse312/18sp/lectures/naive-bayes/naivebayesnotes.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZitX810MSTi"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tar7-wrNQtJ"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvPtymoGYagG",
        "outputId": "5315a262-23ed-49cc-fd80-b3e75ad99ded"
      },
      "source": [
        "from nltk import download\n",
        "download('punkt')\n",
        "download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHW8Ne6Dk6jJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uaIVqzlFROr"
      },
      "source": [
        "class DataPrepration:\n",
        "  \"\"\"\n",
        "    Class for preparing data\n",
        "  \"\"\"\n",
        "  def loadDataset(self, path):\n",
        "    \"\"\"\n",
        "      Load the dataset from path\n",
        "      Param:\n",
        "        str path: to the data\n",
        "      Return:\n",
        "        Dataframe_obj df\n",
        "    \"\"\"\n",
        "    \n",
        "    return pd.read_csv(path, header=0, index_col = 0)\n",
        "  \n",
        "  def splitDataset(self, dataset, train_ratio = 0.8, seed = 1):\n",
        "    \"\"\"\n",
        "      Split a data frame into train, valid, and test set\n",
        "      Param:\n",
        "        # # Dataframe_obj dataset: the dataset\n",
        "        # float train_ratio (default: 0.8): the proportion of the train/dataset\n",
        "        # int seed (default: 1): the randomness seed for shuffling the dataset\n",
        "      Return:\n",
        "        # Dataframe_obj train\n",
        "        # Dataframe_obj test\n",
        "        # Dataframe_obj valid\n",
        "    \"\"\"\n",
        "    train, test = np.split(dataset.sample(frac=1, random_state= seed), [int(train_ratio*len(dataset))])\n",
        "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0., random_state=42)\n",
        "    return train, test\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqJLrWUvIT5h"
      },
      "source": [
        "class DataAnalysis:\n",
        "  \"\"\"\n",
        "    Class to analyse the dataset\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "      Constructor\n",
        "      Param:\n",
        "        # Dataframe_obj dataset \n",
        "    \"\"\"\n",
        "    self.dataset = None\n",
        "    self.S_count = 0 \n",
        "    self.H_count = 0\n",
        "    self.wordsSpamList = []\n",
        "    self.wordsHamList = []\n",
        "    self.wordsSpamSet = ()\n",
        "    self.wordsHamSet = ()\n",
        "\n",
        "  def analyse(self, dataset):\n",
        "    \"\"\"\n",
        "      Analyse a dataset\n",
        "      Param:\n",
        "        # Dataframe_obj dataset\n",
        "    \"\"\"\n",
        "    self.dataset = dataset\n",
        "    self.__set_SandH_count()\n",
        "    self.__set_SandH_wordsList()\n",
        "  \n",
        "  def __set_SandH_count(self):\n",
        "    \"\"\"\n",
        "      Set the S_count and H_count \n",
        "    \"\"\"\n",
        "    freq_table = self.dataset[GLOBAL_label].value_counts().to_dict()\n",
        "    self.S_count = freq_table[GLOBAL_label_yes] if(GLOBAL_label_yes in freq_table.keys()) else 0\n",
        "    self.H_count = freq_table[GLOBAL_label_no] if(GLOBAL_label_no in freq_table.keys()) else 0\n",
        "\n",
        "  def __set_SandH_wordsList(self):\n",
        "    \"\"\"\n",
        "      \n",
        "    \"\"\"\n",
        "    lmtzr = WordNetLemmatizer()\n",
        "    self.wordsSpamList = [[lmtzr.lemmatize(word) for word in word_tokenize(row)] for row in self.dataset[self.dataset[GLOBAL_label] == GLOBAL_label_yes][GLOBAL_value]]\n",
        "    self.wordsSpamList = [item for sublist in self.wordsSpamList for item in sublist] # flatten the nested list\n",
        "    self.wordsSpamSet = set(self.wordsSpamList)\n",
        "\n",
        "    self.wordsHamList = [[lmtzr.lemmatize(word) for word in word_tokenize(row)] for row in self.dataset[self.dataset[GLOBAL_label] == GLOBAL_label_no][GLOBAL_value]]\n",
        "    self.wordsHamList = [item for sublist in self.wordsHamList for item in sublist] # flatten the nested list\n",
        "    self.wordsHamSet = set(self.wordsHamList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_tlvF7bTkJQ"
      },
      "source": [
        "class NaiveBayes:\n",
        "  \"\"\"\n",
        "    Class for the Naive Bayes model\n",
        "    Attributes:\n",
        "      # dict wS_freq: the frequency of words given Spam\n",
        "      # dict wH_freq: the frequency of words given Ham\n",
        "      # dict wS_chance: the P(w|S) value for each word\n",
        "      # dict wH_chance: the P(w|H) value for each word\n",
        "      # float S_chance: the P(S)\n",
        "      # float H_chane: the P(H) \n",
        "      # DataAnalysis_obj dtAnalysis\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "      Constructor\n",
        "    \"\"\"\n",
        "    self.dataAnalysis = None\n",
        "    self.wS_freq = {}\n",
        "    self.wH_freq = {}\n",
        "    self.wS_chance = {}\n",
        "    self.wH_chance = {}\n",
        "    self.S_chance = 0\n",
        "    self.H_chance = 0\n",
        "    \n",
        "  def fit(self, train_dataset):\n",
        "    \"\"\"\n",
        "      Train the model\n",
        "      Param:\n",
        "        # Dataframe_obj train_dataset\n",
        "    \"\"\"\n",
        "    self.dataAnalysis = DataAnalysis()\n",
        "    self.dataAnalysis.analyse(train_dataset)\n",
        "    \n",
        "    self.__calc_wS_freq()\n",
        "    self.__calc_wS_chance()\n",
        "    \n",
        "    self.__calc_wH_freq()\n",
        "    self.__calc_wH_chance()\n",
        "\n",
        "    self.__calc_S_chance()\n",
        "    self.__calc_H_chance()\n",
        "    \n",
        "  def __calc_wS_freq(self):\n",
        "    \"\"\"\n",
        "      Create the dictionary of p(w|S)\n",
        "    \"\"\"\n",
        "    for word in self.dataAnalysis.wordsSpamList:\n",
        "      if(word in self.wS_freq):\n",
        "        self.wS_freq[word] += 1\n",
        "      else:\n",
        "        self.wS_freq[word] = 1\n",
        "  \n",
        "  def __calc_wH_freq(self):\n",
        "    \"\"\"\n",
        "      Create the dictionary of p(w|H)\n",
        "    \"\"\"\n",
        "    for word in self.dataAnalysis.wordsHamList:\n",
        "      if(word in self.wH_freq):\n",
        "        self.wH_freq[word] += 1\n",
        "      else:\n",
        "        self.wH_freq[word] = 1\n",
        "\n",
        "  def __calc_wS_chance(self):\n",
        "    \"\"\"\n",
        "      Create the dictionary of p(w|S)\n",
        "    \"\"\"\n",
        "    for word, freq in self.wS_freq.items():\n",
        "      self.wS_chance[word] = (freq + 1)/(self.dataAnalysis.S_count + 2)\n",
        "  \n",
        "  def __calc_wH_chance(self):\n",
        "    \"\"\"\n",
        "      Create the dictionary of p(w|H)\n",
        "    \"\"\"\n",
        "    for word, freq in self.wH_freq.items():\n",
        "      self.wH_chance[word] = (freq + 1)/(self.dataAnalysis.H_count + 2)\n",
        "\n",
        "  def __calc_S_chance(self):\n",
        "    \"\"\"\n",
        "      Calc the ratio of S over the total emails\n",
        "    \"\"\"\n",
        "    self.S_chance = self.dataAnalysis.S_count / (self.dataAnalysis.S_count + self.dataAnalysis.H_count)\n",
        "\n",
        "  def __calc_H_chance(self):\n",
        "    \"\"\"\n",
        "      Calc the ratio of H over the total emails\n",
        "    \"\"\"\n",
        "    self.H_chance = self.dataAnalysis.H_count / (self.dataAnalysis.S_count + self.dataAnalysis.H_count)\n",
        "\n",
        "  def calc_ultimate_possibility(self, test_sample):\n",
        "    \"\"\"\n",
        "      Calculate the ultimate possibility of P(S|x)\n",
        "      Param:\n",
        "        # Dataframe_obj test_sample: this is expect to contains 1 sample only\n",
        "    \"\"\"\n",
        "    # Analyse the test_dataset\n",
        "    test_dataAnalysis = DataAnalysis()\n",
        "    test_dataAnalysis.analyse(test_sample.transpose()) \n",
        "    test_wordsSpamSet = test_dataAnalysis.wordsSpamSet\n",
        "    test_wordsHamSet = test_dataAnalysis.wordsHamSet\n",
        "\n",
        "    # Calculate the product of all p(x|S) of the test dataset\n",
        "    wS_common = set(self.wS_chance.keys()).intersection(test_wordsSpamSet) # find common element between sets of words in train and test\n",
        "    wS_product = 1\n",
        "    for word in wS_common:\n",
        "      wS_product *= self.wS_chance[word]\n",
        "\n",
        "    # Calculate the product of all p(x|H) of the test dataset\n",
        "    wH_common = set(self.wH_chance.keys()).intersection(test_wordsHamSet) # find common element between sets of words in train and test\n",
        "    wH_product = 1\n",
        "    for word in wH_common:\n",
        "      wH_product *= self.wH_chance[word]\n",
        "\n",
        "    return np.log(self.S_chance * wS_product) / (np.log(self.S_chance * wS_product) + np.log(self.H_chance * wH_product))\n",
        "    \n",
        "  def classify(self, test_dataset):\n",
        "    \"\"\"\n",
        "      Classify the unseen dataset\n",
        "      Param:\n",
        "        # DataFrame_obj test_dataset\n",
        "    \"\"\" \n",
        "    return test_dataset.apply(lambda row: GLOBAL_label_yes if self.calc_ultimate_possibility(row.to_frame()) > GLOBAL_spamThreshold else GLOBAL_label_no, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wMi85jGHDMu"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score\n",
        "class Evaluation:\n",
        "  \"\"\"\n",
        "    Class for evaluating models\n",
        "  \"\"\"\n",
        "  def getEvaluation(self, true, pred):\n",
        "    \"\"\"\n",
        "      Return metric scores for the model\n",
        "      Param:\n",
        "        # list true: the true list\n",
        "        # list pred: the predicted list\n",
        "      Return:\n",
        "        # dict _: the dictionary of metrics\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(true, pred),\n",
        "        \"precision\": precision_score(true, pred),\n",
        "        \"recall\": recall_score(true, pred),\n",
        "        \"auc\": roc_auc_score(true, pred)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akXwcjlXMZ7c"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnh5BfN9KRSA",
        "outputId": "d051e8ed-fee3-4bba-8b5e-75332041a545"
      },
      "source": [
        "\"\"\"\n",
        "  Global value\n",
        "\"\"\"\n",
        "GLOBAL_label = \"label_num\"\n",
        "GLOBAL_label_yes = 1\n",
        "GLOBAL_label_no = 0\n",
        "GLOBAL_value = \"text\"\n",
        "GLOBAL_spamThreshold = 0.5\n",
        "GLOBAL_pred = \"pred\"\n",
        "\n",
        "\"\"\" \n",
        "  Prepare data\n",
        "\"\"\"\n",
        "dataPreperation = DataPrepration()\n",
        "df = dataPreperation.loadDataset('/content/spam_ham_dataset.csv')\n",
        "train, test = dataPreperation.splitDataset(dataset = df, train_ratio = 0.8, seed = 2)\n",
        "\n",
        "\"\"\"\n",
        "  Analyse data. \n",
        "  This DataAnalysis object is a copy of the DataAnalysis object created while training the model.\n",
        "  This obj is used for visualisation only.\n",
        "\"\"\"\n",
        "# dataAnalysis = DataAnalysis()\n",
        "# dataAnalysis.analyse(train)\n",
        "\n",
        "\"\"\"\n",
        "  Train model\n",
        "\"\"\"\n",
        "model = NaiveBayes()\n",
        "model.fit(train)\n",
        "\n",
        "\"\"\"\n",
        "  Test and evaluate\n",
        "\"\"\"\n",
        "print(\"Test dataset\")\n",
        "test[GLOBAL_pred] = model.classify(test)\n",
        "test_metrics = Evaluation().getEvaluation(test[GLOBAL_label], test[GLOBAL_pred])\n",
        "print(test_metrics)\n",
        "\n",
        "print(\"Train dataset\")\n",
        "train[GLOBAL_pred] = model.classify(train)\n",
        "train_metrics = Evaluation().getEvaluation(train[GLOBAL_label], train[GLOBAL_pred])\n",
        "print(train_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset\n",
            "{'accuracy': 0.961352657004831, 'precision': 0.996415770609319, 'recall': 0.8769716088328076, 'auc': 0.9377894255863202}\n",
            "Train dataset\n",
            "{'accuracy': 0.9540618955512572, 'precision': 0.9979919678714859, 'recall': 0.8409475465313029, 'auc': 0.9201352492304449}\n"
          ]
        }
      ]
    }
  ]
}